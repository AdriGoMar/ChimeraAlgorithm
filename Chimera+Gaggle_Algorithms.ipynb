{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 4869,
     "status": "ok",
     "timestamp": 1664958399810,
     "user": {
      "displayName": "ADRIAN GOMEZ MARTIN",
      "userId": "14178073362973308985"
     },
     "user_tz": -120
    },
    "id": "wprasz7XtW0c"
   },
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import ndimage, misc\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import math\n",
    "from pathlib import *\n",
    "import re\n",
    "import random\n",
    "import copy\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from numba import cuda\n",
    "import gc\n",
    "import datetime\n",
    "from PIL import Image as im\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import ndimage, misc\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import math\n",
    "from pathlib import *\n",
    "import re\n",
    "import random\n",
    "import copy\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from numba import cuda\n",
    "import gc\n",
    "import datetime\n",
    "from PIL import Image as im\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from torchvision import datasets, transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1664958399812,
     "user": {
      "displayName": "ADRIAN GOMEZ MARTIN",
      "userId": "14178073362973308985"
     },
     "user_tz": -120
    },
    "id": "3MJhyhoot-eN"
   },
   "outputs": [],
   "source": [
    "def free_gpu_cache():\n",
    "# This function is used to clear the GPU cache and avoid memory problems when dealing with large populations and big models\n",
    "    gc.collect()\n",
    "    torch.cuda.ipc_collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "\n",
    "class FoodSource:\n",
    "# The food sources will hold the models and represent the position in the hyperspace where the algorithm's agents are\n",
    "    def __init__(self, net, fs_exhaustion_limit, cycle_length, max_cycles, lr_bounds):\n",
    "        self.food = net # The food source's core is the model to be improved\n",
    "        self.fs_exhaustion_limit = fs_exhaustion_limit # Number of times a food source can be exploited before considering it exhausted (local minimum)\n",
    "        self.cycle_length = cycle_length\n",
    "        self.stepsize = self.cycle_length * len(train_loader) # According to L.N.Smith, sz = 2-10 times the epoch length\n",
    "        self.lrs = np.concatenate([np.linspace(lr_bounds[0], lr_bounds[1], num = self.stepsize, endpoint = False), np.linspace(lr_bounds[1], lr_bounds[0], num = self.stepsize, endpoint = False)])\n",
    "        self.t_epochs = max_cycles * cycle_length # Max epochs to be trained, unless the model starts overfitting\n",
    "        self.optimizer = optim.Adam(self.food.parameters(), self.lrs[0])\n",
    "\n",
    "        self.fs_exhaustion = 0\n",
    "        self.nectar = 0\n",
    "        self.nectar_ev = [0]\n",
    "        self.train_loss_ev = [0]\n",
    "        self.val_loss_ev = [0]\n",
    "\n",
    "    def mutate_feature_extractor(self, mut_amount = 1, max_layers = 150, max_k_size = 5, c_p_ratio = 5, reset_prob = 0.7, operations = [\"add\", \"mut\", \"del\", \"res\"], op_weights = [3, 3, 3, 1]):\n",
    "    # This function takes a model and mutates its layer as to obtain a distinct but similar one\n",
    "        deprecated = True\n",
    "\n",
    "        while deprecated:\n",
    "            #mut_amount = int(abs(np.random.normal(loc=1.0, scale=(1+self.fs_exhaustion)**1/3))+1)\n",
    "            try:\n",
    "                for m in range(mut_amount):\n",
    "                    model_mutated = copy.deepcopy(self.food)\n",
    "                    mut_type = random.choices(operations, weights = op_weights)[0]\n",
    "                    features = 0\n",
    "                    if mut_type == \"add\" and len(model_mutated.features) < max_layers:\n",
    "                        self.add_layer(model_mutated, max_k_size, c_p_ratio)\n",
    "                        features = 1\n",
    "                    elif mut_type == \"mut\":\n",
    "                        self.mut_layer(model_mutated, max_k_size)\n",
    "                        features = 1\n",
    "                    elif mut_type == \"del\" and len(model_mutated.features) > 2:\n",
    "                        self.del_layer(model_mutated)\n",
    "                        features = 1\n",
    "                    elif mut_type == \"cav\":\n",
    "                        self.change_avg_pool(model_mutated)\n",
    "                        features = 1\n",
    "                    elif mut_type == \"res\":\n",
    "                        self.reset_weights(model_mutated, reset_prob)\n",
    "                        features = 1\n",
    "                    elif mut_type == \"clr\":\n",
    "                        self.change_lr()\n",
    "\n",
    "                self.prune_model(model_mutated)\n",
    "\n",
    "                output_size = [0, model_mutated.avgpool.output_size[0], model_mutated.avgpool.output_size[1]]\n",
    "                index = len(model_mutated.features)\n",
    "                while output_size[0] == 0 and index > 0:\n",
    "                    index -= 1\n",
    "                    if type(model_mutated.features[index]) == torch.nn.modules.conv.Conv2d:\n",
    "                        output_size[0] = model_mutated.features[index].out_channels\n",
    "\n",
    "                for dim in output_size:\n",
    "                    features = features*dim\n",
    "\n",
    "                if features > 0:\n",
    "                    deprecated = False\n",
    "            except:\n",
    "                deprecated = True\n",
    "\n",
    "        model_mutated.classifier = nn.Sequential(torch.nn.modules.activation.ReLU(inplace = True),\n",
    "                                                 nn.Linear(in_features=int(features), out_features=500, bias=True),\n",
    "                                                 torch.nn.modules.activation.ReLU(inplace = True),\n",
    "                                                 torch.nn.modules.dropout.Dropout(p = 0.5, inplace = False),\n",
    "                                                 nn.Linear(in_features=500, out_features=10, bias=True),nn.LogSoftmax(dim=1))\n",
    "        self.food = copy.deepcopy(model_mutated)\n",
    "\n",
    "    def prune_model(self, model_mutated, print_change = False):\n",
    "    # This function makes sure that the model layers do not present incongruent patterns\n",
    "        if print_change:\n",
    "            print(\"Pruning model\")\n",
    "        \n",
    "        index = 1\n",
    "        condition = True\n",
    "        while condition:\n",
    "            if type(model_mutated.features[index]) == torch.nn.modules.conv.Conv2d:\n",
    "                cl = \"conv\"\n",
    "            elif type(model_mutated.features[index]) == torch.nn.modules.pooling.MaxPool2d or type(model_mutated.features[index]) == torch.nn.modules.pooling.AvgPool2d:\n",
    "                cl = \"pool\"\n",
    "            elif type(model_mutated.features[index]) == torch.nn.modules.activation.ReLU or type(model_mutated.features[index]) == torch.nn.Tanh or type(model_mutated.features[index]) == torch.nn.Sigmoid:\n",
    "                cl = \"act_fun\"\n",
    "            if type(model_mutated.features[index-1]) == torch.nn.modules.conv.Conv2d:\n",
    "                pl = \"conv\"\n",
    "            elif type(model_mutated.features[index-1]) == torch.nn.modules.pooling.MaxPool2d or type(model_mutated.features[index-1]) == torch.nn.modules.pooling.AvgPool2d:\n",
    "                pl = \"pool\"\n",
    "            elif type(model_mutated.features[index-1]) == torch.nn.modules.activation.ReLU or type(model_mutated.features[index-1]) == torch.nn.Tanh or type(model_mutated.features[index-1]) == torch.nn.Sigmoid:\n",
    "                pl = \"act_fun\"\n",
    "            \n",
    "            if pl == \"conv\" and cl == \"conv\": # We add a ReLU between two consecutive conv layers\n",
    "                model_mutated.features = nn.Sequential(*list(model_mutated.features.children())[:index], torch.nn.modules.activation.ReLU(inplace = True), *list(model_mutated.features.children())[index:])\n",
    "                index = 0\n",
    "            elif pl == \"act_fun\" and cl == \"pool\": # If an act function precedes a pooling layer, they are switched \n",
    "                model_mutated.features = nn.Sequential(*list(model_mutated.features.children())[:index-1], model_mutated.features[index], model_mutated.features[index-1], *list(model_mutated.features.children())[index+1:])\n",
    "                index = 0\n",
    "            elif pl == cl: # If two layers are the same (but not conv), the first one is removed\n",
    "                model_mutated.features = nn.Sequential(*list(model_mutated.features.children())[:index-1], *list(model_mutated.features.children())[index:])\n",
    "                index = 0\n",
    "            index += 1\n",
    "            condition = index < len(model_mutated.features)\n",
    "    \n",
    "    def change_lr(self, print_change = False):\n",
    "        new_lr_min = random.choice([1e-2, 5e-2, 1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5, 1e-6]) # Gotta make this an input\n",
    "        new_lr_range = random.choice([5, 10, 20]) # Gotta make this an input\n",
    "        self.lrs = np.concatenate([np.linspace(new_lr_min, new_lr_min*new_lr_range, num = self.stepsize, endpoint = False), np.linspace(new_lr_min*new_lr_range, new_lr_min, num = self.stepsize, endpoint = False)])\n",
    "        if print_change:\n",
    "            print(\"Learning rate updated.\")\n",
    "    \n",
    "    def change_avg_pool(self, model_mutated , print_change = False):\n",
    "        max_out_size = 50 # Gotta make this an input\n",
    "        model_mutated.avgpool = nn.AdaptiveAvgPool2d([random.randint(1, max_out_size), random.randint(1, max_out_size)])\n",
    "        \n",
    "    def add_layer(self, model_mutated, max_k_size, c_p_ratio, print_change = False):\n",
    "        cw = 0.01\n",
    "        pw = 0.01\n",
    "        #afw = 0.01\n",
    "        for layer in model_mutated.features:\n",
    "            if type(layer) == torch.nn.modules.conv.Conv2d:\n",
    "                cw += 1\n",
    "            elif type(layer) == torch.nn.modules.pooling.MaxPool2d or type(layer) == torch.nn.modules.pooling.AvgPool2d:\n",
    "                pw += 1\n",
    "            #elif type(layer) == torch.nn.ReLU() or type(layer) == torch.nn.Tanh() or type(layer) == torch.nn.Sigmoid():\n",
    "                #afw += 1\n",
    "        layer_type = random.choices([\"conv\", \"pool\"], weights = [c_p_ratio/cw, 1/pw], k = 1)[0] # , \"act_fun\", 1/afw\n",
    "        index = random.randint(1, len(model_mutated.features))\n",
    "\n",
    "        if print_change:\n",
    "            print(\"Inserting\", layer_type, \"at layer\", index)\n",
    "        if layer_type == \"pool\":\n",
    "            pool_type = random.choice([\"max\", \"avg\"])\n",
    "            k_size = random.randint(2, max_k_size)\n",
    "            st = random.randint(1, k_size)\n",
    "            if pool_type == \"max\":\n",
    "                new_layer = nn.MaxPool2d(kernel_size=k_size, stride=st, padding=0)\n",
    "            elif pool_type == \"avg\":\n",
    "                new_layer = nn.AvgPool2d(kernel_size=k_size, stride=st, padding=0)\n",
    "\n",
    "        elif layer_type == \"act_fun\":\n",
    "            new_layer = nn.ReLU()\n",
    "\n",
    "        elif layer_type == \"conv\":\n",
    "            dim = 0 # The inserted convolutional layer will have the same input feature maps as output ones as to fit within\n",
    "            index_search = index\n",
    "            while dim == 0:\n",
    "                index_search -= 1\n",
    "                if index_search < 0:\n",
    "                    dim = 1\n",
    "                    break\n",
    "                if type(model_mutated.features[index_search]) == torch.nn.modules.conv.Conv2d:\n",
    "                    dim = model_mutated.features[index_search].out_channels\n",
    "            k_size = (random.randint(1, max_k_size), random.randint(1, max_k_size))\n",
    "            st = (random.randint(1, k_size[0]), random.randint(1, k_size[1]))\n",
    "            pad = (random.randint(0, int(k_size[0]/2)), random.randint(0, int(k_size[1]/2)))\n",
    "            new_layer = nn.Conv2d(dim, dim, kernel_size=k_size, stride=st, padding=pad)\n",
    "\n",
    "        model_mutated.features = nn.Sequential(*list(model_mutated.features.children())[:index], new_layer, *list(model_mutated.features.children())[index:])\n",
    "\n",
    "    def mut_layer(self, model_mutated, max_k_size, print_change = False):\n",
    "        f_size_variab = 2\n",
    "\n",
    "        index = random.randint(0, len(model_mutated.features)-1)\n",
    "        index_end = index+1\n",
    "        if print_change:\n",
    "            print(\"Mutating layer\", index)\n",
    "\n",
    "        if type(model_mutated.features[index]) == torch.nn.modules.conv.Conv2d:\n",
    "            dim_in = model_mutated.features[index].in_channels\n",
    "            dim_out = max(1, random.randint(int(model_mutated.features[index].out_channels/f_size_variab), min(int(model_mutated.features[index].out_channels*f_size_variab), 512)))\n",
    "            k_size = (random.randint(1, max_k_size), random.randint(1, max_k_size))\n",
    "            st = (random.randint(1, k_size[0]), random.randint(1, k_size[1]))\n",
    "            pad = (random.randint(0, int(k_size[0]/2)), random.randint(0, int(k_size[1]/2)))\n",
    "            mut_layer = nn.Conv2d(dim_in, dim_out, kernel_size=k_size, stride=st, padding=pad)\n",
    "            while index_end < len(model_mutated.features) and type(model_mutated.features[index_end]) != torch.nn.modules.conv.Conv2d:\n",
    "                index_end += 1\n",
    "            if index_end < len(model_mutated.features):\n",
    "                fixed_layer = nn.Conv2d(dim_out, model_mutated.features[index_end].out_channels, kernel_size=model_mutated.features[index_end].kernel_size, stride=model_mutated.features[index_end].stride, padding=model_mutated.features[index_end].padding)\n",
    "                model_mutated.features = nn.Sequential(*list(model_mutated.features.children())[:index], mut_layer, *list(model_mutated.features.children())[index+1:index_end], fixed_layer, *list(model_mutated.features.children())[index_end+1:])\n",
    "            else:\n",
    "                model_mutated.features = nn.Sequential(*list(model_mutated.features.children())[:index], mut_layer, *list(model_mutated.features.children())[index+1:])\n",
    "\n",
    "        elif type(model_mutated.features[index]) == torch.nn.modules.pooling.MaxPool2d or type(model_mutated.features[index]) == torch.nn.modules.pooling.AvgPool2d:\n",
    "            pool_type = random.choice([\"max\", \"avg\"])\n",
    "            k_size = random.randint(2, max_k_size)\n",
    "            st = random.randint(1, k_size)\n",
    "            if pool_type == \"max\":\n",
    "                mut_layer = nn.MaxPool2d(kernel_size=k_size, stride=st, padding=0)\n",
    "            elif pool_type == \"avg\":\n",
    "                mut_layer = nn.AvgPool2d(kernel_size=k_size, stride=st, padding=0)\n",
    "            model_mutated.features = nn.Sequential(*list(model_mutated.features.children())[:index], mut_layer, *list(model_mutated.features.children())[index_end:])\n",
    "\n",
    "        elif type(model_mutated.features[index]) == torch.nn.modules.ReLU or type(model_mutated.features[index]) == torch.nn.modules.Tanh or type(model_mutated.features[index]) == torch.nn.modules.Sigmoid:\n",
    "            mut_layer = nn.ReLU()\n",
    "            model_mutated.features = nn.Sequential(*list(model_mutated.features.children())[:index], mut_layer, *list(model_mutated.features.children())[index_end:])\n",
    "\n",
    "    def del_layer(self, model_mutated, print_change = False):\n",
    "        index = random.randint(0, len(model_mutated.features)-1)\n",
    "        index_end = index+1\n",
    "        if print_change:\n",
    "            print(\"Deleting layer\", index)\n",
    "\n",
    "        if type(model_mutated.features[index]) == torch.nn.modules.conv.Conv2d:\n",
    "            dim_in = model_mutated.features[index].in_channels\n",
    "            while index_end < len(model_mutated.features) and type(model_mutated.features[index_end]) != torch.nn.modules.conv.Conv2d:\n",
    "                index_end += 1\n",
    "            if index_end < len(model_mutated.features):\n",
    "                fixed_layer = nn.Conv2d(dim_in, model_mutated.features[index_end].out_channels, kernel_size=model_mutated.features[index_end].kernel_size, stride=model_mutated.features[index_end].stride, padding=model_mutated.features[index_end].padding)\n",
    "                model_mutated.features = nn.Sequential(*list(model_mutated.features.children())[:index], *list(model_mutated.features.children())[index+1:index_end], fixed_layer, *list(model_mutated.features.children())[index_end+1:])\n",
    "            else:\n",
    "                model_mutated.features = nn.Sequential(*list(model_mutated.features.children())[:index], *list(model_mutated.features.children())[index+1:])\n",
    "\n",
    "        # If it is a pooling or activation function layer we get rid of it directly\n",
    "        elif type(model_mutated.features[index]) == torch.nn.modules.ReLU or type(model_mutated.features[index]) == torch.nn.modules.Tanh or type(model_mutated.features[index]) == torch.nn.modules.Sigmoid or type(model_mutated.features[index]) == torch.nn.modules.pooling.MaxPool2d or type(model_mutated.features[index]) == torch.nn.modules.pooling.AvgPool2d:\n",
    "            model_mutated.features = nn.Sequential(*list(model_mutated.features.children())[:index], *list(model_mutated.features.children())[index_end:])\n",
    "\n",
    "    def reset_weights(self, model_mutated, reset_prob, print_change = False): # Reinitialize the predictor's weights\n",
    "        reseted_layers = []\n",
    "        for index in range(len(model_mutated.features)):\n",
    "            if type(model_mutated.features[index]) == torch.nn.modules.conv.Conv2d and random.random() < reset_prob:\n",
    "                reseted_layers += [index]\n",
    "                nn.init.xavier_uniform_(model_mutated.features[index].weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "        if print_change:\n",
    "            print(\"Weights reseted on layers\", reseted_layers)\n",
    "    \n",
    "    def train_fs(self):\n",
    "    # This function is used to train the model for a certain number of epochs\n",
    "        self.food.to(device)\n",
    "        loss_tra = []\n",
    "        loss_val = []\n",
    "        nectar_ev = []\n",
    "        overfit = 0\n",
    "        lr_index = 0\n",
    "        invalid = False\n",
    "        with tqdm(total=self.t_epochs, leave = False, desc='Training') as pbar1:\n",
    "            for epoch in range(self.t_epochs): # loop over the dataset multiple times\n",
    "                running_loss = 0.0\n",
    "                with tqdm(total=len(train_loader), leave = False, desc='Epoch progress') as pbar2:\n",
    "                    for i, data in enumerate(train_loader, 0):\n",
    "                        if lr_index >= len(self.lrs)-1:\n",
    "                            lr_index -= len(self.lrs)\n",
    "                        lr_index += 1\n",
    "                        #self.optimizer = optim.SGD(self.food.parameters(), self.lrs[lr_index], self.moms[lr_index])\n",
    "                        self.optimizer = optim.Adam(self.food.parameters(), self.lrs[lr_index])\n",
    "                        # get the inputs; data is a list of [inputs, labels]\n",
    "                        inputs, labels = data\n",
    "                        inputs, labels = inputs.to(device), labels.to(device)\n",
    "                        # zero the parameter gradients\n",
    "                        self.optimizer.zero_grad()\n",
    "                        # forward + backward + optimize\n",
    "                        \n",
    "                        try:\n",
    "                            outputs = self.food(inputs).squeeze()\n",
    "                        except:\n",
    "                            invalid = True\n",
    "                            pbar2.update(len(train_loader))\n",
    "                            break\n",
    "                        \n",
    "                        loss = criterion(outputs, labels)\n",
    "                        #print(loss)\n",
    "                        loss.backward()\n",
    "                        self.optimizer.step()\n",
    "                        running_loss += loss.item()\n",
    "                        #loss_tra += [loss.item()]\n",
    "                        pbar2.update(1)\n",
    "                        if bool(np.isnan(loss.cpu().detach())):\n",
    "                            invalid = True\n",
    "                            pbar2.update(len(train_loader))\n",
    "                            break\n",
    "                # We keep track of the losses and nectar evolutions\n",
    "                if invalid:\n",
    "                    pbar1.update(self.t_epochs)\n",
    "                    break\n",
    "                loss_tra += [running_loss/len(train_loader)]\n",
    "                current_loss_val = self.validate_fs()\n",
    "                loss_val += [current_loss_val]\n",
    "                nectar_ev += [fitness_function(current_loss_val)]\n",
    "                pbar1.update(1)\n",
    "                if len(nectar_ev) > 4: # We let it train for at least 4 epoch\n",
    "                    # If the model's loss converges or starts increasing, we keep track\n",
    "                    if np.mean(loss_val[-4:]) - np.mean(loss_val[-3:]) < 0.001:\n",
    "                        overfit += 1\n",
    "                    else:\n",
    "                        overfit = 0\n",
    "                if overfit >= 3: # self.cycle_length: # If the nectar decreases for an entire cycle we assume overfitting\n",
    "                    pbar1.update(self.t_epochs)\n",
    "                    break\n",
    "        if not invalid:\n",
    "            self.nectar_ev = copy.deepcopy(nectar_ev)\n",
    "            self.train_loss_ev = copy.deepcopy(loss_tra)\n",
    "            self.val_loss_ev = copy.deepcopy(loss_val)\n",
    "            self.nectar = copy.deepcopy(np.mean(nectar_ev[-4:]))\n",
    "        self.food.to(\"cpu\")\n",
    "        \n",
    "        # We get rid of everything we don't need\n",
    "        del loss_tra, loss_val, nectar_ev, overfit, lr_index, pbar1, pbar2, running_loss, i, data, self.optimizer, inputs, labels\n",
    "        free_gpu_cache()\n",
    "        return invalid\n",
    "    \n",
    "    \n",
    "        \n",
    "    def validate_fs(self):\n",
    "    # This function is used to test the accuracy of a given model on the validation dataset\n",
    "        total_loss = 0\n",
    "        total_iter = 0\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        self.food.eval()\n",
    "        with tqdm(total=len(val_loader), leave = False, desc = \"Checking current performance\") as pbar:\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    images, labels = data\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = self.food(images).squeeze()\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    total_iter += 1\n",
    "                    total_loss += loss.item()\n",
    "                    pbar.update(1)\n",
    "        del images, labels, data, loss\n",
    "        self.food.train()\n",
    "        return total_loss / total_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainloop_weighted(fs, t_epochs, train_dloader, val_dloader, lr = 1e-3, show_plots=False):\n",
    "    model = fs.food\n",
    "    \n",
    "    try:\n",
    "        model.to(device)\n",
    "\n",
    "        criterion = nn.NLLLoss()\n",
    "\n",
    "        best_val = np.inf\n",
    "        loss_tra = []\n",
    "        loss_val = []\n",
    "        overfit = 0\n",
    "        lr = lr\n",
    "        optimizer = optim.Adam(model.parameters(), lr)\n",
    "\n",
    "        #with tqdm(total=t_epochs, leave = False, desc='Training') as pbar1:\n",
    "        for epoch in range(t_epochs): # loop over the dataset multiple times\n",
    "            running_loss = 0.0\n",
    "            #with tqdm(total=len(train_dloader), leave = False, desc='Epoch progress') as pbar2:\n",
    "            for i, data in enumerate(train_dloader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward + backward + optimize\n",
    "                outputs = model(inputs).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                #pbar2.update(1)\n",
    "            # We keep track of the losses and nectar evolutions\n",
    "            loss_tra += [running_loss/len(train_dloader)]\n",
    "\n",
    "            val_total_loss = 0\n",
    "            # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "            model.eval()\n",
    "            #with tqdm(total=len(val_dloader), leave = False, desc = \"Checking model performance\") as pbar:\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_dloader:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs = model(inputs).squeeze()\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_total_loss += loss.item()\n",
    "                    #pbar.update(1)\n",
    "            model.train()\n",
    "            loss_val += [val_total_loss / len(val_dloader)]\n",
    "            #pbar1.update(1)\n",
    "\n",
    "            if best_val > loss_val[-1]:\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_model.to(\"cpu\")\n",
    "                best_val = loss_val[-1]\n",
    "                best_train = loss_tra[-1]\n",
    "                overfit = 0\n",
    "            else:\n",
    "                overfit += 1\n",
    "\n",
    "            if overfit >= 10:\n",
    "                #pbar1.update(t_epochs)\n",
    "                break\n",
    "\n",
    "        model = copy.deepcopy(best_model)\n",
    "\n",
    "        if show_plots == True:\n",
    "            plt.plot(loss_val)\n",
    "            plt.plot(loss_tra)\n",
    "            plt.show()\n",
    "            print()\n",
    "            print(\"Best validation loss:       \", best_val)\n",
    "            print(\"Corresponding training loss:\", best_train)\n",
    "\n",
    "        # We get rid of everything we don't need\n",
    "        fs.nectar = fitness_function(best_val)\n",
    "\n",
    "        del overfit, running_loss, i, data, optimizer, inputs, labels, loss #, pbar1, pbar2\n",
    "        free_gpu_cache()\n",
    "        invalid = False\n",
    "    \n",
    "    except:\n",
    "        invalid = True\n",
    "    \n",
    "    fs.food = model\n",
    "    \n",
    "    return fs, invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_ensemble(models, weights, dataloader, model_weighting = \"mean\"):\n",
    "    equals = np.zeros(len(dataloader.dataset.targets))\n",
    "    total_probs = np.zeros((len(dataloader.dataset.targets),10))\n",
    "    with torch.no_grad():\n",
    "        for m, model in enumerate(models):\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            probs = np.empty((0,10))\n",
    "            for images,labels in dataloader:\n",
    "                images,labels = images.to(device),labels.to(device)\n",
    "                new_probs = torch.exp(model.forward(images)).cpu().numpy()\n",
    "                probs = np.append(probs, new_probs, 0)\n",
    "            probs_aux = np.zeros((len(dataloader.dataset.targets),10))\n",
    "            for label in range(10):\n",
    "                if model_weighting == \"cm\":\n",
    "                    probs_aux[:,label] = probs@weights[m][:,label]\n",
    "                else:\n",
    "                    probs_aux = probs*weights[m]\n",
    "            total_probs += probs_aux\n",
    "            model.to(\"cpu\")\n",
    "            model.train()\n",
    "        top_class = np.argmax(total_probs,1)\n",
    "        equals = top_class == dataloader.dataset.targets\n",
    "        \n",
    "    return equals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1664958399812,
     "user": {
      "displayName": "ADRIAN GOMEZ MARTIN",
      "userId": "14178073362973308985"
     },
     "user_tz": -120
    },
    "id": "a9cJ0vH4ueIW"
   },
   "outputs": [],
   "source": [
    "#@title Bee classes and Nectar function\n",
    "class EmployedBee:\n",
    "# Each Employed Bee has an associated food source and will only exploit that one\n",
    "    def __init__(self, fs, bee_number):\n",
    "        self.fs = fs\n",
    "        self.b_type = \"employed\"\n",
    "        self.scouting = False\n",
    "        self.bee_number = bee_number\n",
    "\n",
    "    def exploit_food_source(self):\n",
    "        try:\n",
    "            invalid = True\n",
    "            while invalid:\n",
    "                new_fs = copy.deepcopy(self.fs)\n",
    "                new_fs.mutate_feature_extractor(int(abs(np.random.normal(loc=1.0, scale=(1+new_fs.fs_exhaustion)**1/3))+1)) # The bee looks for a food source nearby\n",
    "                new_fs, invalid = trainloop_weighted(new_fs, 100, train_loader_weights, val_loader, lr = 3e-3, show_plots=False)\n",
    "                #invalid = new_fs.train_fs() # and evaluates if it produces better nectar than the original one\n",
    "\n",
    "                #plt.subplot(Np, 2, 2*self.bee_number+1) # We plot both for comparisson\n",
    "                #plt.plot(new_fs.train_loss_ev)\n",
    "                #plt.plot(new_fs.val_loss_ev)\n",
    "                #plt.legend([\"Original food source\", \"Mutated food source\"])\n",
    "                #plt.title(\"Food source's new nectar: \" + str(new_fs.nectar))\n",
    "                #plt.show()\n",
    "\n",
    "                if new_fs.nectar > self.fs.nectar: # If it is indeed better, the bee will change food source\n",
    "                    self.fs = copy.deepcopy(new_fs)\n",
    "                    self.fs.fs_exhaustion = 0\n",
    "                    return 1\n",
    "                else: # If not, the bee will forget about the new food source and add 1 to the exhaustion counter\n",
    "                    self.fs.fs_exhaustion += 1\n",
    "                    if self.fs.fs_exhaustion >= self.fs.fs_exhaustion_limit: # If the food source doesn't have any better ones nearby, it is considered a local minima\n",
    "                        self.scouting = True\n",
    "                    return 0\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "class OnlookerBee:\n",
    "# Onlooker bees will look at all current food sources and exploit the ones that look more promising\n",
    "    def __init__(self, bee_number):\n",
    "        self.b_type = \"onlooker\"\n",
    "        self.bee_number = bee_number\n",
    "\n",
    "    def scout_food_source(self, b_ffss, b_nectars):\n",
    "        chosen_fs = True\n",
    "        while chosen_fs: # If the random number generated does not match the probability of\n",
    "            if random.random() > b_nectars[0]/sum(b_nectars): # the current food source being chosen,\n",
    "                b_ffss = b_ffss[1:] + [b_ffss[0]] # we send that food source to the back of the list\n",
    "                b_nectars = b_nectars[1:] + [b_nectars[0]]\n",
    "            else:\n",
    "                b_ffss = b_ffss[1:] + [b_ffss[0]]\n",
    "                b_nectars = b_nectars[1:] + [b_nectars[0]]\n",
    "                chosen_fs = False\n",
    "        \n",
    "        try:\n",
    "            invalid = True\n",
    "            while invalid:\n",
    "                new_fs = copy.deepcopy(b_ffss[-1]) # If it does, we exploit it following the same procedure as for Employed Bees\n",
    "\n",
    "                new_fs.mutate_feature_extractor(int(abs(np.random.normal(loc=1.0, scale=(1+new_fs.fs_exhaustion)**1/3))+1)) # The bee looks for a food source nearby\n",
    "                new_fs, invalid = trainloop_weighted(new_fs, 100, train_loader_weights, val_loader, lr = 3e-3, show_plots=False)\n",
    "                #invalid = new_fs.train_fs() # and evaluates if it produces better nectar than the original one\n",
    "\n",
    "                #plt.subplot(Np, 2, 2*self.bee_number+2)\n",
    "                #plt.plot(new_fs.train_loss_ev)\n",
    "                #plt.plot(new_fs.val_loss_ev)\n",
    "                #plt.legend([\"Original food source\", \"Mutated food source\"])\n",
    "                #plt.title(\"Food source's new nectar: \" + str(new_fs.nectar))\n",
    "                #plt.show()\n",
    "\n",
    "                if new_fs.nectar > b_ffss[0].nectar:\n",
    "                    b_ffss[0] = copy.deepcopy(new_fs)\n",
    "                    b_ffss[0].fs_exhaustion = 0\n",
    "                    return 1, b_ffss, b_nectars\n",
    "                else:\n",
    "                    b_ffss[0].fs_exhaustion += 1\n",
    "                    return 0, b_ffss, b_nectars\n",
    "        except:\n",
    "            return 0, b_ffss, b_nectars\n",
    "\n",
    "def fitness_function(score):\n",
    "# This is the fitness function to retrieve the nectar amount as defined for the ABC algorithm\n",
    "    if score >= 0:\n",
    "        fitness = 1 / (1 + score)\n",
    "    else:\n",
    "        fitness = 1 + abs(score)\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights(model, dataloader):\n",
    "    total_probs = np.zeros((len(dataloader.dataset.targets),10))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    probs = np.empty((0,10))\n",
    "    with torch.no_grad():\n",
    "        for images,labels in dataloader:\n",
    "            images,labels = images.to(device),labels.to(device)\n",
    "            new_probs = torch.exp(model.forward(images)).cpu().numpy()\n",
    "            probs = np.append(probs, new_probs, 0)\n",
    "    model.to(\"cpu\")\n",
    "    model.train()\n",
    "    top_class = np.argmax(probs,1)\n",
    "    weights = np.zeros((10,10))\n",
    "    # We generate the confussion matrix\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            weights[i,j] = np.mean(top_class[np.array(dataloader.dataset.targets) == i]==j)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1664958491163,
     "user": {
      "displayName": "ADRIAN GOMEZ MARTIN",
      "userId": "14178073362973308985"
     },
     "user_tz": -120
    },
    "id": "xZSpbBWkIaJi"
   },
   "outputs": [],
   "source": [
    "#@title Beehive class (gotta define the model outside the class and call it)\n",
    "class Beehive:\n",
    "    def __init__(self, Np = 5, model_name = \"[custom net]\", fs_exhaustion_limit = 15, cycle_length = 8, max_cycles = 8, lr_bounds = [5e-6, 5e-5]):\n",
    "        \n",
    "        self.bees = []\n",
    "        self.ex_ffss = []\n",
    "        self.ffss = []\n",
    "        self.Np = Np\n",
    "        free_gpu_cache()\n",
    "\n",
    "        model = torch.hub.load('pytorch/vision:v0.10.0', \"vgg11\", pretrained=True)\n",
    "\n",
    "        model.features = nn.Sequential(nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
    "        model.avgpool = nn.AdaptiveAvgPool2d([10, 10])\n",
    "\n",
    "        output_size = [0, model.avgpool.output_size[0], model.avgpool.output_size[1]]\n",
    "        index = len(model.features)\n",
    "        while output_size[0] == 0:\n",
    "            index -= 1\n",
    "            if type(model.features[index]) == torch.nn.modules.conv.Conv2d:\n",
    "                output_size[0] = model.features[index].out_channels\n",
    "\n",
    "        features = 1\n",
    "        for dim in output_size:\n",
    "            features = features*dim\n",
    "\n",
    "        model.classifier = nn.Sequential(nn.Linear(in_features=int(features), out_features=500, bias=True),\n",
    "                                                torch.nn.modules.activation.ReLU(inplace = True),\n",
    "                                                torch.nn.modules.dropout.Dropout(p = 0.5, inplace = False),\n",
    "                                                nn.Linear(in_features=500, out_features=10, bias=True), \n",
    "                                                nn.LogSoftmax(dim=1))\n",
    "\n",
    "        #os.chdir(\"D:\\\\adri\")\n",
    "        #model = torch.load(\"saved_models\\\\uoffset\\\\2022_03_27_22_03_31.pt\")\n",
    "\n",
    "        #model.classifier = nn.Sequential(*list(model.classifier.children()), nn.ReLU(), nn.Linear(1000, 10))\n",
    "\n",
    "        self.original_fs = FoodSource(net = model, fs_exhaustion_limit = fs_exhaustion_limit, cycle_length = cycle_length, max_cycles = max_cycles, lr_bounds = lr_bounds)\n",
    "        self.original_fs, invalid = trainloop_weighted(self.original_fs, 100, train_loader_weights, val_loader, lr = 3e-3, show_plots=False)\n",
    "        \n",
    "        #self.original_fs.train_fs()\n",
    "\n",
    "        with tqdm(total=self.Np, leave = False, desc = \"Initializing population\") as pbar:\n",
    "            for b in range(self.Np):\n",
    "                invalid = True\n",
    "                while invalid:\n",
    "                    base_fs = copy.deepcopy(self.original_fs)\n",
    "                    base_fs.mutate_feature_extractor(15)\n",
    "                    base_fs, invalid = trainloop_weighted(base_fs, 100, train_loader_weights, val_loader, lr = 3e-3, show_plots=False)\n",
    "                    #invalid = base_fs.train_fs()\n",
    "                self.bees += [EmployedBee(copy.deepcopy(base_fs), b)]\n",
    "                pbar.update(1)\n",
    "        for b in range(self.Np):\n",
    "            self.bees += [OnlookerBee(b)]\n",
    "\n",
    "        self.current_iter = 0\n",
    "    \n",
    "    def find_foodsource(self, perf_thresh = 0, max_iter = 30):\n",
    "        while self.current_iter < max_iter:\n",
    "            self.current_iter += 1\n",
    "            print(\"\")\n",
    "            print(\"Iteration\", self.current_iter, \"of the algorithm\")\n",
    "            nectars = []\n",
    "                \n",
    "            #print(\"Employed Bee Phase\")\n",
    "            b = 0\n",
    "            c = 0\n",
    "            self.ffss = []\n",
    "            with tqdm(total=self.Np, leave = False, desc = \"Employed bee phase\") as pbar:\n",
    "                for bee in self.bees:    # Employed bee phase\n",
    "                    if bee.b_type == \"employed\":\n",
    "                        b += 1\n",
    "                        #print(\"    Employed Bee #\" + str(b))\n",
    "                        c += bee.exploit_food_source()\n",
    "                        pbar.update(1)\n",
    "                        if bee.fs.fs_exhaustion >= bee.fs.fs_exhaustion_limit:\n",
    "                            bee.scouting = True\n",
    "                        self.ffss += [bee.fs]\n",
    "                        nectars += [bee.fs.nectar]\n",
    "            print(c, \"better food sources found during employed bee phase\")\n",
    "            \n",
    "            #print(\"Onlooking Bee Phase\")\n",
    "            b = 0\n",
    "            c = 0\n",
    "            with tqdm(total=self.Np, leave = False, desc = \"Onlooker bee phase\") as pbar:\n",
    "                for bee in self.bees:  # Scouting bee phase\n",
    "                    if bee.b_type == \"onlooker\":\n",
    "                        b += 1\n",
    "                        #print(\"    Onlooker Bee #\" + str(b))\n",
    "                        a, self.ffss, nectars= bee.scout_food_source(self.ffss, nectars)\n",
    "                        c += a\n",
    "                        pbar.update(1)\n",
    "            print(c, \"better food sources found during onlooker bee phase\")\n",
    "            \n",
    "            #print(\"Scouting Bee Phase\")\n",
    "            a = 0\n",
    "            b = 0\n",
    "            with tqdm(total=self.Np, leave = False, desc = \"Scouting bee phase\") as pbar:\n",
    "                for bee in self.bees:    # Scouting bee phase\n",
    "                    if bee.b_type == \"employed\":\n",
    "                        bee.fs = self.ffss[a]\n",
    "                        a += 1\n",
    "                        pbar.update(1)\n",
    "                        if bee.scouting:\n",
    "                            b += 1\n",
    "                            #print(\"    Scouting Bee #\" + str(b)+ \"reseted food source\")\n",
    "                            self.ex_ffss += [copy.deepcopy(bee.fs)]\n",
    "                            invalid = True\n",
    "                            while invalid:\n",
    "                                base_fs = copy.deepcopy(self.original_fs)\n",
    "                                base_fs.mutate_feature_extractor(15)\n",
    "                                base_fs, invalid = trainloop_weighted(base_fs, 100, train_loader_weights, val_loader, lr = 3e-3, show_plots=False)\n",
    "                            bee.fs = copy.deepcopy(base_fs)\n",
    "                            bee.scouting = False\n",
    "            if b == 0:\n",
    "                print(\"No bees in scouting mode\")\n",
    "            else:\n",
    "                print(c, \"bees entered scouting mode\")\n",
    "\n",
    "        if self.current_iter == max_iter:\n",
    "            print(\"Algorithm unable to find suitable food source in\", self.current_iter, \"iterations.\")\n",
    "    \n",
    "        free_gpu_cache()\n",
    "        return [copy.deepcopy(fs.food) for fs in self.ex_ffss + self.ffss]\n",
    "\n",
    "    def save_models(self, folder = \"saved_models\\\\\", directory = os.getcwd()):\n",
    "        os.chdir(directory)\n",
    "        run_id = str(datetime.datetime.today())\n",
    "        for i in range(len(run_id)):\n",
    "            if run_id[i] == \"-\" or run_id[i] == \" \" or run_id[i] == \":\":\n",
    "                run_id = run_id[:i]+\"_\"+run_id[i+1:]\n",
    "            elif run_id[i] == \".\":\n",
    "                run_id = run_id[:i]\n",
    "                break\n",
    "        model_save_path = folder+run_id\n",
    "        if not os.path.exists(model_save_path):\n",
    "          os.makedirs(model_save_path)\n",
    "\n",
    "        models = [bee.fs for bee in self.bees[:self.Np]] + self.ex_ffss\n",
    "        for i in range(len(models)):\n",
    "            model = copy.deepcopy(models[i])\n",
    "            torch.save(model.food, model_save_path+\"\\\\\"+str(np.mean(model.val_loss_ev[-4:]))+\".pt\")\n",
    "\n",
    "        del model, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name, folder = \"saved_models\\\\\"):\n",
    "    \n",
    "    if not os.path.exists(folder):\n",
    "      os.makedirs(folder)\n",
    "\n",
    "    torch.save(model, folder+\"\\\\\"+name+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hives = 4\n",
    "Np = 4\n",
    "data_weighting = \"fail_resample\"\n",
    "model_weighting = \"val_weight\"\n",
    "save_models = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"GPU available:\", device == torch.device('cuda'))\n",
    "\n",
    "# Download and load the training data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = datasets.CIFAR10('~/.pytorch/CIFAR10_data/', download=True, train=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=False)\n",
    "val_loader = copy.deepcopy(train_loader)\n",
    "# Permutate dataset for crossvalidation\n",
    "idx_shuffled = np.arange(len(train_loader.dataset.targets))\n",
    "np.random.shuffle(idx_shuffled)\n",
    "\n",
    "#We take 45k random images for training\n",
    "train_loader.dataset.data = train_loader.dataset.data[idx_shuffled[:45000],:,:]\n",
    "train_loader.dataset.targets = [train_loader.dataset.targets[idx] for idx in idx_shuffled[:45000]]\n",
    "\n",
    "# We create another one that suffles, is subjected to change and holds the weights of the datapoints\n",
    "train_loader_weights = torch.utils.data.DataLoader(copy.deepcopy(train_loader.dataset), batch_size=64, shuffle=True)\n",
    "\n",
    "#And the rest for validation\n",
    "val_loader.dataset.data = val_loader.dataset.data[idx_shuffled[45000:],:,:]\n",
    "val_loader.dataset.targets = [val_loader.dataset.targets[idx] for idx in idx_shuffled[45000:]]\n",
    "\n",
    "# Fetch the test data as well\n",
    "testset = datasets.CIFAR10('~/.pytorch/CIFAR10_data/', download=True, train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False)\n",
    "\n",
    "# Generate folder to save run\n",
    "folder_path = \"D:\\\\adri\\\\iisgm\\\\2022_2023\\\\saved_models_Deepsemble\\\\CIFAR100_Chimera_\"+data_weighting+\"_\"+model_weighting\n",
    "run_id = str(datetime.datetime.today())\n",
    "for i in range(len(run_id)):\n",
    "    if run_id[i] == \"-\" or run_id[i] == \":\":\n",
    "        run_id = run_id[:i]+\"_\"+run_id[i+1:]\n",
    "    elif run_id[i] == \" \":\n",
    "        run_id = run_id[:i]\n",
    "        break\n",
    "folder_path = folder_path+run_id+\"_0\"\n",
    "\n",
    "i = 0\n",
    "while os.path.exists(folder_path):\n",
    "    i += 1\n",
    "    folder_path = folder_path[:-2]+\"_\"+str(i)\n",
    "\n",
    "# Generate models\n",
    "models_list = []\n",
    "model_weights = []\n",
    "model_acc = []\n",
    "t_acc = np.empty((0,0))\n",
    "v_acc = np.empty((0,0))\n",
    "test_acc = np.empty((0,0))\n",
    "\n",
    "for n in range(n_hives):\n",
    "    start_time = time.time()\n",
    "    hive = Beehive(Np = Np, model_name = \"[CIFAR-10 test]\", fs_exhaustion_limit = 15, cycle_length = 8, max_cycles = 8, lr_bounds = [5e-6, 5e-5])\n",
    "    model_batch = hive.find_foodsource(perf_thresh = 0, max_iter = 16)\n",
    "    \n",
    "    print(len(model_batch), \"models added to the ensemble in\", time.time()-start_time, \"seconds\")\n",
    "    \n",
    "    for m, model in enumerate(model_batch):\n",
    "        save_model(model, name = str(len(models_list)+m), folder = folder_path)\n",
    "        model_weights += [calculate_weights(model, val_loader)]\n",
    "        model_acc += [np.sum(np.diagonal(model_weights[-1]))/np.sum(model_weights[-1])]\n",
    "        \n",
    "    models_list += model_batch\n",
    "\n",
    "    # Calculate performances on the datasets\n",
    "    if model_weighting == \"mean\":\n",
    "        train_equals = validate_ensemble(models_list, np.ones(len(model_acc)), train_loader, model_weighting = model_weighting)\n",
    "        t_acc = np.append(t_acc, np.mean(train_equals))\n",
    "        v_acc = np.append(v_acc, np.mean(validate_ensemble(models_list, np.ones(len(model_acc)), val_loader, model_weighting = model_weighting)))\n",
    "        test_acc = np.append(test_acc, np.mean(validate_ensemble(models_list, np.ones(len(model_acc)), test_loader, model_weighting = model_weighting)))\n",
    "    elif model_weighting == \"val_weight\":\n",
    "        train_equals = validate_ensemble(models_list, model_acc, train_loader, model_weighting = model_weighting)\n",
    "        t_acc = np.append(t_acc, np.mean(train_equals))\n",
    "        v_acc = np.append(v_acc, np.mean(validate_ensemble(models_list, model_acc, val_loader, model_weighting = model_weighting)))\n",
    "        test_acc = np.append(test_acc, np.mean(validate_ensemble(models_list, model_acc, test_loader, model_weighting = model_weighting)))\n",
    "    elif model_weighting == \"cm\":\n",
    "        train_equals = validate_ensemble(models_list, model_weights, train_loader, model_weighting = model_weighting)\n",
    "        t_acc = np.append(t_acc, np.mean(train_equals))\n",
    "        v_acc = np.append(v_acc, np.mean(validate_ensemble(models_list, model_weights, val_loader, model_weighting = model_weighting)))\n",
    "        test_acc = np.append(test_acc, np.mean(validate_ensemble(models_list, model_weights, test_loader, model_weighting = model_weighting)))\n",
    "\n",
    "    # Resample or weight the dataset\n",
    "    if data_weighting == \"fail_resample\":\n",
    "        train_loader_updated = torch.utils.data.DataLoader(copy.deepcopy(train_loader.dataset), batch_size=64, shuffle=True)\n",
    "        train_loader_updated.dataset.data = train_loader_updated.dataset.data[~train_equals,:,:]\n",
    "        train_loader_updated.dataset.targets = [train_loader_updated.dataset.targets[idx] for idx in np.arange(len(train_equals))[~train_equals]]\n",
    "    elif data_weighting == \"acc_resample\":\n",
    "        weights = np.ones(len(train_loader.dataset.targets))\n",
    "        weights = weights*np.exp(1-(2*train_equals)*np.mean(train_equals))\n",
    "        weights /= np.sum(weights) # Normalize\n",
    "        new_indexes = np.random.choice([int(d) for d in range(len(weights))], len(weights), p=weights)\n",
    "        train_loader_updated = copy.deepcopy(train_loader)\n",
    "        train_loader_updated.dataset.data = train_loader.dataset.data[new_indexes,:,:]\n",
    "        train_loader_updated.dataset.targets = [train_loader.dataset.targets[i]for i in new_indexes]\n",
    "    elif data_weighting == \"data_weights\":\n",
    "        total_train_acc = np.sum(train_equals)/len(train_equals)\n",
    "        weights = np.exp((1-(2*train_equals))*total_train_acc)\n",
    "        weights = weights/np.mean(weights)\n",
    "        train_loader_weights.dataset.targets[:,1] = weights\n",
    "\n",
    "# We order the models according to their validation accuracy\n",
    "model_acc = []\n",
    "for con_matrix in model_weights:\n",
    "    model_acc += [np.sum(np.diagonal(con_matrix))/np.sum(con_matrix)]\n",
    "indexes_sorted = np.flip(np.argsort(model_acc))\n",
    "\n",
    "t_acc_sorted = np.empty((0,0))\n",
    "v_acc_sorted = np.empty((0,0))\n",
    "test_acc_sorted = np.empty((0,0))\n",
    "#with tqdm(total=len(models_list), leave = False, desc = \"Calculating ensemble performance evolution\") as pbarm:\n",
    "for n in range(len(models_list)):\n",
    "    if model_weighting == \"mean\":\n",
    "        t_acc_sorted = np.append(t_acc_sorted, np.mean(validate_ensemble([models_list[m] for m in indexes_sorted[:n+1]], np.ones(n+1), train_loader, model_weighting = model_weighting)))\n",
    "        v_acc_sorted = np.append(v_acc_sorted, np.mean(validate_ensemble([models_list[m] for m in indexes_sorted[:n+1]], np.ones(n+1), val_loader, model_weighting = model_weighting)))\n",
    "        test_acc_sorted = np.append(test_acc_sorted, np.mean(validate_ensemble([models_list[m] for m in indexes_sorted[:n+1]], np.ones(n+1), test_loader, model_weighting = model_weighting)))\n",
    "    elif model_weighting == \"val_weight\":\n",
    "        t_acc_sorted = np.append(t_acc_sorted, np.mean(validate_ensemble([models_list[m] for m in indexes_sorted[:n+1]], [model_acc[m] for m in indexes_sorted[:n+1]], train_loader, model_weighting = model_weighting)))\n",
    "        v_acc_sorted = np.append(v_acc_sorted, np.mean(validate_ensemble([models_list[m] for m in indexes_sorted[:n+1]], [model_acc[m] for m in indexes_sorted[:n+1]], val_loader, model_weighting = model_weighting)))\n",
    "        test_acc_sorted = np.append(test_acc_sorted, np.mean(validate_ensemble([models_list[m] for m in indexes_sorted[:n+1]], [model_acc[m] for m in indexes_sorted[:n+1]], test_loader, model_weighting = model_weighting)))\n",
    "    elif model_weighting == \"cm\":\n",
    "        t_acc_sorted = np.append(t_acc_sorted, np.mean(validate_ensemble([models_list[m] for m in indexes_sorted[:n+1]], [model_weights[m] for m in indexes_sorted[:n+1]], train_loader, model_weighting = model_weighting)))\n",
    "        v_acc_sorted = np.append(v_acc_sorted, np.mean(validate_ensemble([models_list[m] for m in indexes_sorted[:n+1]], [model_weights[m] for m in indexes_sorted[:n+1]], val_loader, model_weighting = model_weighting)))\n",
    "        test_acc_sorted = np.append(test_acc_sorted, np.mean(validate_ensemble([models_list[m] for m in indexes_sorted[:n+1]], [model_weights[m] for m in indexes_sorted[:n+1]], test_loader, model_weighting = model_weighting)))\n",
    "    #pbarm.update(1)\n",
    "\n",
    "t_acc_complete = np.empty((0,0))\n",
    "v_acc_complete = np.empty((0,0))\n",
    "test_acc_complete = np.empty((0,0))\n",
    "#with tqdm(total=len(models_list), leave = False, desc = \"Calculating ensemble performance evolution\") as pbarm:\n",
    "for n in range(len(models_list)):\n",
    "    if model_weighting == \"mean\":\n",
    "        t_acc_complete = np.append(t_acc_complete, np.mean(validate_ensemble(models_list[:n+1], np.ones(n+1), train_loader, model_weighting = model_weighting)))\n",
    "        v_acc_complete = np.append(v_acc_complete, np.mean(validate_ensemble(models_list[:n+1], np.ones(n+1), val_loader, model_weighting = model_weighting)))\n",
    "        test_acc_complete = np.append(test_acc_complete, np.mean(validate_ensemble(models_list[:n+1], np.ones(n+1), test_loader, model_weighting = model_weighting)))\n",
    "    #pbarm.update(1)\n",
    "\n",
    "max_ensemble_train = [max(t_acc)]\n",
    "max_ensemble_val   = [max(v_acc)]\n",
    "max_ensemble_test  = [max(test_acc)]\n",
    "max_sorted_train   = [max(t_acc_sorted)]\n",
    "max_sorted_val     = [max(v_acc_sorted)]\n",
    "max_sorted_test    = [max(test_acc_sorted)]\n",
    "max_ensemble_train_complete = [max(t_acc_complete)]\n",
    "max_ensemble_val_complete   = [max(v_acc_complete)]\n",
    "max_ensemble_test_complete  = [max(test_acc_complete)]\n",
    "print(\"max_ensemble_train =\", max_ensemble_train)\n",
    "print(\"max_ensemble_val =\", max_ensemble_val)\n",
    "print(\"max_ensemble_test =\", max_ensemble_test)\n",
    "print(\"max_sorted_train =\", max_sorted_train)\n",
    "print(\"max_sorted_val =\", max_sorted_val)\n",
    "print(\"max_sorted_test =\", max_sorted_test)\n",
    "print(\"max_ensemble_train_complete =\", max_ensemble_train_complete)\n",
    "print(\"max_ensemble_val_complete =\", max_ensemble_val_complete)\n",
    "print(\"max_ensemble_test_complete =\", max_ensemble_test_complete)\n",
    "\n",
    "plt.plot(t_acc)\n",
    "plt.plot(v_acc)\n",
    "plt.plot(test_acc)\n",
    "plt.show\n",
    "plt.plot(t_acc_sorted)\n",
    "plt.plot(v_acc_sorted)\n",
    "plt.plot(test_acc_sorted)\n",
    "plt.show\n",
    "plt.plot(t_acc_complete)\n",
    "plt.plot(v_acc_complete)\n",
    "plt.plot(test_acc_complete)\n",
    "plt.show\n",
    "\n",
    "print(\"t_acc\" + f\"{np.mean(t_acc):.5f}\" + \" ± \" + f\"{np.std(t_acc):.5f}\")\n",
    "print(\"v_acc\" + f\"{np.mean(v_acc):.5f}\" + \" ± \" + f\"{np.std(v_acc):.5f}\")\n",
    "print(\"test_acc\" + f\"{np.mean(test_acc):.5f}\" + \" ± \" + f\"{np.std(test_acc):.5f}\")\n",
    "print(\"t_acc_sorted\" + f\"{np.mean(t_acc_sorted):.5f}\" + \" ± \" + f\"{np.std(t_acc_sorted):.5f}\")\n",
    "print(\"v_acc_sorted\" + f\"{np.mean(v_acc_sorted):.5f}\" + \" ± \" + f\"{np.std(v_acc_sorted):.5f}\")\n",
    "print(\"test_acc_sorted\" + f\"{np.mean(test_acc_sorted):.5f}\" + \" ± \" + f\"{np.std(test_acc_sorted):.5f}\")\n",
    "print(\"t_acc_complete\" + f\"{np.mean(t_acc_complete):.5f}\" + \" ± \" + f\"{np.std(t_acc_complete):.5f}\")\n",
    "print(\"v_acc_complete\" + f\"{np.mean(v_acc_complete):.5f}\" + \" ± \" + f\"{np.std(v_acc_complete):.5f}\")\n",
    "print(\"test_acc_complete\" + f\"{np.mean(test_acc_complete):.5f}\" + \" ± \" + f\"{np.std(test_acc_complete):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO+XDjEVjVteea2Byby1pjM",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01361d28366848fc80b5ea82b55b9d16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07579903110d4b5ca8b3df5b3b9d617f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a80e8b4a1794e58b10834a307a486e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "10831b9360c2467c831a01b558ff59cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b622ee611e354df1b1af4c22ab397bac",
      "placeholder": "​",
      "style": "IPY_MODEL_ee81ac9621c242daba670581088b8415",
      "value": "100%"
     }
    },
    "12467900f18d4b0fad8271c424557c19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26a1016fc1ff49a2be8192a54414f123": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2da71bbdec28487fba7459d864438237": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3244cd5b72e64c19bfd74b412e03fe30",
      "max": 4422102,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ad6e64f41a614195b945353b3e099018",
      "value": 4422102
     }
    },
    "2ebf04c430b148a49ecd0a717b190269": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3244cd5b72e64c19bfd74b412e03fe30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "338c4b6c7f12471a8c98db82aade0fe2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "35d9168c4068458dbde7d3cf29d0c98f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5f17fe874aa34089bd79cbc172079872",
       "IPY_MODEL_c6dd56153e3a4ecb9ab6bfad7556f60d",
       "IPY_MODEL_bf3f6fafb70e48768fd87c1570fb3ac5"
      ],
      "layout": "IPY_MODEL_ef9bf4ba615a40c9b6b4f170a7ea5165"
     }
    },
    "3d56a0ccedd94a41a60ae5f6d98816fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_10831b9360c2467c831a01b558ff59cb",
       "IPY_MODEL_624086e73a6b470396a87cbf35864298",
       "IPY_MODEL_5e57ded0987e438ea0c87a344d8d12b0"
      ],
      "layout": "IPY_MODEL_9626caa3669b4d439e769933fcf64805"
     }
    },
    "4041c36b028340f38f37955665024d8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc5b4fe20f9b45df97661389543c3be7",
      "placeholder": "​",
      "style": "IPY_MODEL_5af55e73fed845339504c6732f94397a",
      "value": " 4422102/4422102 [00:00&lt;00:00, 15721832.95it/s]"
     }
    },
    "44aa29effd4e498f8a93f1a09cfe4c20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4eb11741428a4805bdc9c362f18e87bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50b74c8873114219b89134347997c473": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "57136cdb89b5409d955b58e02abb81a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5af55e73fed845339504c6732f94397a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e57ded0987e438ea0c87a344d8d12b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd2d00c892224c21ac1aa01eca7d70a0",
      "placeholder": "​",
      "style": "IPY_MODEL_0a80e8b4a1794e58b10834a307a486e6",
      "value": " 5148/5148 [00:00&lt;00:00, 140658.05it/s]"
     }
    },
    "5f17fe874aa34089bd79cbc172079872": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01361d28366848fc80b5ea82b55b9d16",
      "placeholder": "​",
      "style": "IPY_MODEL_44aa29effd4e498f8a93f1a09cfe4c20",
      "value": "100%"
     }
    },
    "614728c97bc34919a421420f576fdf24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98d700350192411383861be5f41054ef",
      "placeholder": "​",
      "style": "IPY_MODEL_4eb11741428a4805bdc9c362f18e87bf",
      "value": "100%"
     }
    },
    "624086e73a6b470396a87cbf35864298": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be938a0c067d47afbb34695cf0482398",
      "max": 5148,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cbc4ce61e11d4c25befc15118f86fbf6",
      "value": 5148
     }
    },
    "6659573ae69a46efadac66dfdee662cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ebf04c430b148a49ecd0a717b190269",
      "max": 26421880,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_338c4b6c7f12471a8c98db82aade0fe2",
      "value": 26421880
     }
    },
    "6c0e29f90fd646699332c057abb7f4bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9c83010ace2443528f6b817f32ec8e09",
       "IPY_MODEL_2da71bbdec28487fba7459d864438237",
       "IPY_MODEL_4041c36b028340f38f37955665024d8a"
      ],
      "layout": "IPY_MODEL_b406d2bfd00a437e81e0b2e316f2c557"
     }
    },
    "745ba5b7145343c19135f7a42cb269f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_614728c97bc34919a421420f576fdf24",
       "IPY_MODEL_6659573ae69a46efadac66dfdee662cd",
       "IPY_MODEL_bef7f85a95f549569a139086c3143fc7"
      ],
      "layout": "IPY_MODEL_eb4cbf60206d4ffab14e7d95a6fde162"
     }
    },
    "930eee82f2164c13925d83ebe197eda4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9626caa3669b4d439e769933fcf64805": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98d700350192411383861be5f41054ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c83010ace2443528f6b817f32ec8e09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26a1016fc1ff49a2be8192a54414f123",
      "placeholder": "​",
      "style": "IPY_MODEL_a4a46e7009004eb78a91af032fc7e997",
      "value": "100%"
     }
    },
    "a4a46e7009004eb78a91af032fc7e997": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ad6e64f41a614195b945353b3e099018": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b406d2bfd00a437e81e0b2e316f2c557": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b622ee611e354df1b1af4c22ab397bac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be938a0c067d47afbb34695cf0482398": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bef7f85a95f549569a139086c3143fc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12467900f18d4b0fad8271c424557c19",
      "placeholder": "​",
      "style": "IPY_MODEL_50b74c8873114219b89134347997c473",
      "value": " 26421880/26421880 [00:00&lt;00:00, 131865827.73it/s]"
     }
    },
    "bf3f6fafb70e48768fd87c1570fb3ac5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57136cdb89b5409d955b58e02abb81a0",
      "placeholder": "​",
      "style": "IPY_MODEL_07579903110d4b5ca8b3df5b3b9d617f",
      "value": " 29515/29515 [00:00&lt;00:00, 794601.13it/s]"
     }
    },
    "c6dd56153e3a4ecb9ab6bfad7556f60d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcb7ae4c5e1f4113bba6170546d4b8ef",
      "max": 29515,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_930eee82f2164c13925d83ebe197eda4",
      "value": 29515
     }
    },
    "cbc4ce61e11d4c25befc15118f86fbf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dc5b4fe20f9b45df97661389543c3be7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcb7ae4c5e1f4113bba6170546d4b8ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb4cbf60206d4ffab14e7d95a6fde162": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee81ac9621c242daba670581088b8415": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef9bf4ba615a40c9b6b4f170a7ea5165": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd2d00c892224c21ac1aa01eca7d70a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
